{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-28 15:47:30,042 - root - INFO - AIMET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-8:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkProcess-6:\n",
      "Traceback (most recent call last):\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Process ForkProcess-4:\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from aimet_torch.batch_norm_fold import fold_all_batch_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-28 15:53:32,393 - timm.models.helpers - INFO - Loading pretrained weights from url (https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth)\n",
      "2025-02-28 15:53:33,381 - ConnectedGraph - WARNING - Unable to isolate model outputs.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = timm.create_model(\"swin_tiny_patch4_window7_224\", pretrained=True)\n",
    "\n",
    "# Define transformation function\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "batch_size = 16\n",
    "val_data_path = \"/media/bmw/datasets/imagenet-1k/val/\"\n",
    "SUBSET_SIZE = 1000\n",
    "val_dataset = torchvision.datasets.ImageFolder(root=val_data_path, transform=preprocess)\n",
    "\n",
    "# Take a subset of the validation dataset\n",
    "subset_indices = list(range(SUBSET_SIZE))  # First `SUBSET_SIZE` samples\n",
    "val_subset = Subset(val_dataset, subset_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "fold_all_batch_norms(model, dummy_input.shape)\n",
    "\n",
    "# Callback function to pass calibration data through the model\n",
    "def pass_calibration_data(model: torch.nn.Module, batches):\n",
    "    with torch.no_grad():\n",
    "        for batch, (images, _) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            model(images)\n",
    "            if batch >= batches:\n",
    "                break\n",
    "\n",
    "# Basic ImageNet evaluation function\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in tqdm(data_loader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            logits = model(data)\n",
    "            correct += (logits.argmax(1) == labels).type(torch.float).sum().item()\n",
    "    accuracy = correct / len(data_loader.dataset)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing and validating the model for quantization...\n",
      "2025-02-28 15:51:19,110 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.0.module_floordiv} \n",
      "2025-02-28 15:51:19,110 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.0.module_floordiv_1} \n",
      "2025-02-28 15:51:19,111 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.0.attn.module_floordiv_2} \n",
      "2025-02-28 15:51:19,111 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.0.attn.module_mul} \n",
      "2025-02-28 15:51:19,112 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.0.attn.module_matmul} \n",
      "2025-02-28 15:51:19,112 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.0.attn.module_add} \n",
      "2025-02-28 15:51:19,113 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.0.attn.module_matmul_1} \n",
      "2025-02-28 15:51:19,113 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.0.module_floordiv_3} \n",
      "2025-02-28 15:51:19,113 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.0.module_add_1} \n",
      "2025-02-28 15:51:19,114 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layers.0.blocks.0.mlp.module_drop_1} \n",
      "2025-02-28 15:51:19,114 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layers.0.blocks.0.module_drop_path_1} \n",
      "2025-02-28 15:51:19,115 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.0.module_add_2} \n",
      "2025-02-28 15:51:19,115 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.1.module_floordiv_4} \n",
      "2025-02-28 15:51:19,115 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.1.module_floordiv_5} \n",
      "2025-02-28 15:51:19,116 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.1.attn.module_floordiv_6} \n",
      "2025-02-28 15:51:19,116 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.1.attn.module_mul_1} \n",
      "2025-02-28 15:51:19,116 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.1.attn.module_matmul_2} \n",
      "2025-02-28 15:51:19,117 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.1.attn.module_add_3} \n",
      "2025-02-28 15:51:19,117 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.1.attn.module_floordiv_7} \n",
      "2025-02-28 15:51:19,118 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.1.attn.module_add_4} \n",
      "2025-02-28 15:51:19,118 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.1.attn.module_matmul_3} \n",
      "2025-02-28 15:51:19,118 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.1.module_floordiv_8} \n",
      "2025-02-28 15:51:19,119 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.1.module_add_5} \n",
      "2025-02-28 15:51:19,119 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layers.0.blocks.1.mlp.module_drop_1} \n",
      "2025-02-28 15:51:19,119 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.blocks.1.module_add_6} \n",
      "2025-02-28 15:51:19,120 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.downsample.module_cat} \n",
      "2025-02-28 15:51:19,120 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.0.downsample.module_mul_2} \n",
      "2025-02-28 15:51:19,120 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.0.module_floordiv_9} \n",
      "2025-02-28 15:51:19,121 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.0.module_floordiv_10} \n",
      "2025-02-28 15:51:19,121 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.0.attn.module_floordiv_11} \n",
      "2025-02-28 15:51:19,122 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.0.attn.module_mul_3} \n",
      "2025-02-28 15:51:19,122 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.0.attn.module_matmul_4} \n",
      "2025-02-28 15:51:19,122 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.0.attn.module_add_7} \n",
      "2025-02-28 15:51:19,123 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.0.attn.module_matmul_5} \n",
      "2025-02-28 15:51:19,123 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.0.module_floordiv_12} \n",
      "2025-02-28 15:51:19,123 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.0.module_add_8} \n",
      "2025-02-28 15:51:19,124 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layers.1.blocks.0.mlp.module_drop_1} \n",
      "2025-02-28 15:51:19,126 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.0.module_add_9} \n",
      "2025-02-28 15:51:19,126 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.1.module_floordiv_13} \n",
      "2025-02-28 15:51:19,127 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.1.module_floordiv_14} \n",
      "2025-02-28 15:51:19,127 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.1.attn.module_floordiv_15} \n",
      "2025-02-28 15:51:19,127 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.1.attn.module_mul_4} \n",
      "2025-02-28 15:51:19,128 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.1.attn.module_matmul_6} \n",
      "2025-02-28 15:51:19,128 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.1.attn.module_add_10} \n",
      "2025-02-28 15:51:19,128 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.1.attn.module_floordiv_16} \n",
      "2025-02-28 15:51:19,129 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.1.attn.module_add_11} \n",
      "2025-02-28 15:51:19,129 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.1.attn.module_matmul_7} \n",
      "2025-02-28 15:51:19,130 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.1.module_floordiv_17} \n",
      "2025-02-28 15:51:19,130 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.1.module_add_12} \n",
      "2025-02-28 15:51:19,130 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layers.1.blocks.1.mlp.module_drop_1} \n",
      "2025-02-28 15:51:19,131 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.blocks.1.module_add_13} \n",
      "2025-02-28 15:51:19,131 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.downsample.module_cat_1} \n",
      "2025-02-28 15:51:19,131 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.1.downsample.module_mul_5} \n",
      "2025-02-28 15:51:19,132 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.0.module_floordiv_18} \n",
      "2025-02-28 15:51:19,132 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.0.module_floordiv_19} \n",
      "2025-02-28 15:51:19,132 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.0.attn.module_floordiv_20} \n",
      "2025-02-28 15:51:19,133 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.0.attn.module_mul_6} \n",
      "2025-02-28 15:51:19,133 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.0.attn.module_matmul_8} \n",
      "2025-02-28 15:51:19,133 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.0.attn.module_add_14} \n",
      "2025-02-28 15:51:19,134 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.0.attn.module_matmul_9} \n",
      "2025-02-28 15:51:19,134 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.0.module_floordiv_21} \n",
      "2025-02-28 15:51:19,135 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.0.module_add_15} \n",
      "2025-02-28 15:51:19,135 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layers.2.blocks.0.mlp.module_drop_1} \n",
      "2025-02-28 15:51:19,135 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.0.module_add_16} \n",
      "2025-02-28 15:51:19,136 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.1.module_floordiv_22} \n",
      "2025-02-28 15:51:19,136 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.1.module_floordiv_23} \n",
      "2025-02-28 15:51:19,136 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.1.attn.module_floordiv_24} \n",
      "2025-02-28 15:51:19,137 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.1.attn.module_mul_7} \n",
      "2025-02-28 15:51:19,137 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.1.attn.module_matmul_10} \n",
      "2025-02-28 15:51:19,137 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.1.attn.module_add_17} \n",
      "2025-02-28 15:51:19,138 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.1.attn.module_floordiv_25} \n",
      "2025-02-28 15:51:19,138 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.1.attn.module_add_18} \n",
      "2025-02-28 15:51:19,138 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.1.attn.module_matmul_11} \n",
      "2025-02-28 15:51:19,139 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.1.module_floordiv_26} \n",
      "2025-02-28 15:51:19,139 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.1.module_add_19} \n",
      "2025-02-28 15:51:19,140 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layers.2.blocks.1.mlp.module_drop_1} \n",
      "2025-02-28 15:51:19,140 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.1.module_add_20} \n",
      "2025-02-28 15:51:19,140 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.2.module_floordiv_27} \n",
      "2025-02-28 15:51:19,141 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.2.module_floordiv_28} \n",
      "2025-02-28 15:51:19,141 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.2.attn.module_floordiv_29} \n",
      "2025-02-28 15:51:19,141 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.2.attn.module_mul_8} \n",
      "2025-02-28 15:51:19,142 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.2.attn.module_matmul_12} \n",
      "2025-02-28 15:51:19,142 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.2.attn.module_add_21} \n",
      "2025-02-28 15:51:19,142 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.2.attn.module_matmul_13} \n",
      "2025-02-28 15:51:19,143 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.2.module_floordiv_30} \n",
      "2025-02-28 15:51:19,143 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.2.module_add_22} \n",
      "2025-02-28 15:51:19,144 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layers.2.blocks.2.mlp.module_drop_1} \n",
      "2025-02-28 15:51:19,144 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.2.module_add_23} \n",
      "2025-02-28 15:51:19,144 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.3.module_floordiv_31} \n",
      "2025-02-28 15:51:19,145 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.3.module_floordiv_32} \n",
      "2025-02-28 15:51:19,145 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.3.attn.module_floordiv_33} \n",
      "2025-02-28 15:51:19,145 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.3.attn.module_mul_9} \n",
      "2025-02-28 15:51:19,146 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.3.attn.module_matmul_14} \n",
      "2025-02-28 15:51:19,146 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.3.attn.module_add_24} \n",
      "2025-02-28 15:51:19,146 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.3.attn.module_floordiv_34} \n",
      "2025-02-28 15:51:19,147 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.3.attn.module_add_25} \n",
      "2025-02-28 15:51:19,147 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.3.attn.module_matmul_15} \n",
      "2025-02-28 15:51:19,147 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.3.module_floordiv_35} \n",
      "2025-02-28 15:51:19,148 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.3.module_add_26} \n",
      "2025-02-28 15:51:19,148 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layers.2.blocks.3.mlp.module_drop_1} \n",
      "2025-02-28 15:51:19,149 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.3.module_add_27} \n",
      "2025-02-28 15:51:19,149 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.4.module_floordiv_36} \n",
      "2025-02-28 15:51:19,149 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.4.module_floordiv_37} \n",
      "2025-02-28 15:51:19,150 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.4.attn.module_floordiv_38} \n",
      "2025-02-28 15:51:19,150 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.4.attn.module_mul_10} \n",
      "2025-02-28 15:51:19,150 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.4.attn.module_matmul_16} \n",
      "2025-02-28 15:51:19,151 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.4.attn.module_add_28} \n",
      "2025-02-28 15:51:19,151 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.4.attn.module_matmul_17} \n",
      "2025-02-28 15:51:19,152 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.4.module_floordiv_39} \n",
      "2025-02-28 15:51:19,152 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.4.module_add_29} \n",
      "2025-02-28 15:51:19,152 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layers.2.blocks.4.mlp.module_drop_1} \n",
      "2025-02-28 15:51:19,156 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.4.module_add_30} \n",
      "2025-02-28 15:51:19,157 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.5.module_floordiv_40} \n",
      "2025-02-28 15:51:19,157 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.5.module_floordiv_41} \n",
      "2025-02-28 15:51:19,158 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.5.attn.module_floordiv_42} \n",
      "2025-02-28 15:51:19,158 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.5.attn.module_mul_11} \n",
      "2025-02-28 15:51:19,158 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.5.attn.module_matmul_18} \n",
      "2025-02-28 15:51:19,159 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.5.attn.module_add_31} \n",
      "2025-02-28 15:51:19,159 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.5.attn.module_floordiv_43} \n",
      "2025-02-28 15:51:19,159 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.5.attn.module_add_32} \n",
      "2025-02-28 15:51:19,160 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.5.attn.module_matmul_19} \n",
      "2025-02-28 15:51:19,160 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.5.module_floordiv_44} \n",
      "2025-02-28 15:51:19,160 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.5.module_add_33} \n",
      "2025-02-28 15:51:19,161 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layers.2.blocks.5.mlp.module_drop_1} \n",
      "2025-02-28 15:51:19,161 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.blocks.5.module_add_34} \n",
      "2025-02-28 15:51:19,162 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.downsample.module_cat_2} \n",
      "2025-02-28 15:51:19,162 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.2.downsample.module_mul_12} \n",
      "2025-02-28 15:51:19,162 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.0.module_floordiv_45} \n",
      "2025-02-28 15:51:19,163 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.0.module_floordiv_46} \n",
      "2025-02-28 15:51:19,163 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.0.attn.module_floordiv_47} \n",
      "2025-02-28 15:51:19,163 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.0.attn.module_mul_13} \n",
      "2025-02-28 15:51:19,164 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.0.attn.module_matmul_20} \n",
      "2025-02-28 15:51:19,164 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.0.attn.module_add_35} \n",
      "2025-02-28 15:51:19,164 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.0.attn.module_matmul_21} \n",
      "2025-02-28 15:51:19,165 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.0.module_floordiv_48} \n",
      "2025-02-28 15:51:19,165 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.0.module_add_36} \n",
      "2025-02-28 15:51:19,165 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layers.3.blocks.0.mlp.module_drop_1} \n",
      "2025-02-28 15:51:19,166 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.0.module_add_37} \n",
      "2025-02-28 15:51:19,166 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.1.module_floordiv_49} \n",
      "2025-02-28 15:51:19,167 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.1.module_floordiv_50} \n",
      "2025-02-28 15:51:19,167 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.1.attn.module_floordiv_51} \n",
      "2025-02-28 15:51:19,167 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.1.attn.module_mul_14} \n",
      "2025-02-28 15:51:19,168 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.1.attn.module_matmul_22} \n",
      "2025-02-28 15:51:19,168 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.1.attn.module_add_38} \n",
      "2025-02-28 15:51:19,168 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.1.attn.module_matmul_23} \n",
      "2025-02-28 15:51:19,169 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.1.module_floordiv_52} \n",
      "2025-02-28 15:51:19,169 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.1.module_add_39} \n",
      "2025-02-28 15:51:19,170 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layers.3.blocks.1.mlp.module_drop_1} \n",
      "2025-02-28 15:51:19,170 - ModelPreparer - INFO - Functional         : Adding new module for node: {layers.3.blocks.1.module_add_40} \n"
     ]
    }
   ],
   "source": [
    "from aimet_torch.model_preparer import prepare_model\n",
    "\n",
    "print(\"\\nPreparing and validating the model for quantization...\")\n",
    "prepared_model = prepare_model(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-28 15:51:29,318 - Utils - INFO - Running validator check <function validate_for_reused_modules at 0x7efd864f2560>\n",
      "2025-02-28 15:51:29,371 - Utils - INFO - Running validator check <function validate_for_missing_modules at 0x7efd7a4360e0>\n",
      "2025-02-28 15:51:39,334 - ConnectedGraph - WARNING - Unable to isolate model outputs.\n",
      "2025-02-28 15:51:39,359 - Utils - ERROR - Functional ops that are not marked as math invariant were found in the model. AIMET features will not work properly for such ops.\n",
      "Consider the following choices: \n",
      "1. Redefine as a torch.nn.Module in the class definition.\n",
      "2. The op can remain as a functional op due to being math invariant, but the op type has not been added to ConnectedGraph.math_invariant_types set. \n",
      "Add an entry to ignore the op by importing the set and adding the op type:\n",
      "\n",
      "\tfrom aimet_torch.meta.connectedgraph import ConnectedGraph\n",
      "\tConnectedGraph.math_invariant_types.add(...)\n",
      "\n",
      "The following functional ops were found. The parent module is named for ease of locating the ops within the model definition.\n",
      "\troll_235; op_type: roll           parent module: GraphModule\n",
      "\troll_399; op_type: roll           parent module: GraphModule\n",
      "\troll_712; op_type: roll           parent module: GraphModule\n",
      "\troll_876; op_type: roll           parent module: GraphModule\n",
      "\troll_1189; op_type: roll          parent module: GraphModule\n",
      "\troll_1353; op_type: roll          parent module: GraphModule\n",
      "\troll_1562; op_type: roll          parent module: GraphModule\n",
      "\troll_1726; op_type: roll          parent module: GraphModule\n",
      "\troll_1935; op_type: roll          parent module: GraphModule\n",
      "\troll_2099; op_type: roll          parent module: GraphModule\n",
      "\n",
      "2025-02-28 15:51:39,360 - Utils - INFO - The following validator checks failed:\n",
      "2025-02-28 15:51:39,360 - Utils - INFO - \t<function validate_for_missing_modules at 0x7efd7a4360e0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aimet_torch.model_validator.model_validator import ModelValidator\n",
    "\n",
    "ModelValidator.validate_model(prepared_model, model_input=torch.rand(1, 3, 224, 224).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimet_torch.meta.connectedgraph import ConnectedGraph\n",
    "ConnectedGraph.math_invariant_types.add(\"roll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-28 15:52:27,345 - Utils - INFO - Running validator check <function validate_for_reused_modules at 0x7efd864f2560>\n",
      "2025-02-28 15:52:27,397 - Utils - INFO - Running validator check <function validate_for_missing_modules at 0x7efd7a4360e0>\n",
      "2025-02-28 15:52:37,069 - ConnectedGraph - WARNING - Unable to isolate model outputs.\n",
      "2025-02-28 15:52:37,095 - Utils - INFO - All validation checks passed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelValidator.validate_model(prepared_model, model_input=torch.rand(1, 3, 224, 224).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-28 15:53:40,858 - ConnectedGraph - WARNING - Unable to isolate model outputs.\n",
      "2025-02-28 15:53:41,046 - Quant - INFO - No config file provided, defaulting to config file at /home/bmw/anaconda3/envs/swin_bhanu/lib/python3.10/site-packages/aimet_common/quantsim_config/default_config.json\n",
      "2025-02-28 15:53:41,068 - Quant - INFO - Unsupported op type Squeeze\n",
      "2025-02-28 15:53:41,069 - Quant - INFO - Unsupported op type Mean\n",
      "2025-02-28 15:53:41,084 - Quant - INFO - Selecting DefaultOpInstanceConfigGenerator to compute the specialized config. hw_version:default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:17<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized accuracy (W8A8): 0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from aimet_common.defs import QuantScheme\n",
    "from aimet_torch.quantsim import QuantizationSimModel\n",
    "from timm.models.layers.drop import DropPath\n",
    "from aimet_torch.v2.nn import QuantizationMixin\n",
    "\n",
    "\n",
    "@QuantizationMixin.implements(DropPath)\n",
    "class QuantizedDropPath(QuantizationMixin, DropPath):\n",
    "    def __quant_init__(self):\n",
    "        super().__quant_init__()\n",
    "        self.input_quantizers = torch.nn.ModuleList([None])\n",
    "        self.output_quantizers = torch.nn.ModuleList([None])\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.input_quantizers[0]:\n",
    "            x = self.input_quantizers[0](x)\n",
    "        with self._patch_quantized_parameters():\n",
    "            ret = super().forward(x)\n",
    "        if self.output_quantizers[0]:\n",
    "            ret = self.output_quantizers[0](ret)\n",
    "        return ret\n",
    "\n",
    "    \n",
    "sim = QuantizationSimModel(model, dummy_input, quant_scheme=QuantScheme.training_range_learning_with_tf_init)\n",
    "\n",
    "calibration_batches = 10\n",
    "sim.compute_encodings(pass_calibration_data, calibration_batches)\n",
    "\n",
    "accuracy = evaluate(sim.model, val_loader)\n",
    "print(f\"Quantized accuracy (W8A8): {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [05:13<00:00,  4.97s/it]\n",
      "100%|██████████| 63/63 [05:17<00:00,  5.04s/it]\n"
     ]
    }
   ],
   "source": [
    "def train(model, data_loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    for data, labels in tqdm(data_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        logits = model(data)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(sim.model.parameters(), lr=1e-5)\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    train(sim.model, val_loader, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:17<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy after QAT: 0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate(sim.model, val_loader)\n",
    "print(f\"Model accuracy after QAT: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swin_bhanu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
